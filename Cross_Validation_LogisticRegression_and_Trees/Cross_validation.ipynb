{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[4-6]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[0-4]'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'Latino/Hispanic American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>b''</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Latino/Hispanic American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[0-5]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>b''</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Other'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'[0-5]'</td>\n",
       "      <td>b'[0-4]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>b''</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'[4-6]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Latino/Hispanic American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>b''</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[0-5]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>b''</td>\n",
       "      <td>21.0</td>\n",
       "      <td>b'male'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[0-5]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     has_null  wave     gender   age  age_o  d_age   d_d_age  \\\n",
       "0         b''   1.0  b'female'  21.0   27.0    6.0  b'[4-6]'   \n",
       "1         b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n",
       "2         b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n",
       "3         b''   1.0  b'female'  21.0   23.0    2.0  b'[2-3]'   \n",
       "4         b''   1.0  b'female'  21.0   24.0    3.0  b'[2-3]'   \n",
       "...       ...   ...        ...   ...    ...    ...       ...   \n",
       "8373      b''  21.0    b'male'  25.0   26.0    1.0  b'[0-1]'   \n",
       "8374      b''  21.0    b'male'  25.0   24.0    1.0  b'[0-1]'   \n",
       "8375      b''  21.0    b'male'  25.0   29.0    4.0  b'[4-6]'   \n",
       "8376      b''  21.0    b'male'  25.0   22.0    3.0  b'[2-3]'   \n",
       "8377      b''  21.0    b'male'  25.0   22.0    3.0  b'[2-3]'   \n",
       "\n",
       "                                          race  \\\n",
       "0     b'Asian/Pacific Islander/Asian-American'   \n",
       "1     b'Asian/Pacific Islander/Asian-American'   \n",
       "2     b'Asian/Pacific Islander/Asian-American'   \n",
       "3     b'Asian/Pacific Islander/Asian-American'   \n",
       "4     b'Asian/Pacific Islander/Asian-American'   \n",
       "...                                        ...   \n",
       "8373            b'European/Caucasian-American'   \n",
       "8374            b'European/Caucasian-American'   \n",
       "8375            b'European/Caucasian-American'   \n",
       "8376            b'European/Caucasian-American'   \n",
       "8377            b'European/Caucasian-American'   \n",
       "\n",
       "                                        race_o samerace  ...  \\\n",
       "0               b'European/Caucasian-American'     b'0'  ...   \n",
       "1               b'European/Caucasian-American'     b'0'  ...   \n",
       "2     b'Asian/Pacific Islander/Asian-American'     b'1'  ...   \n",
       "3               b'European/Caucasian-American'     b'0'  ...   \n",
       "4                  b'Latino/Hispanic American'     b'0'  ...   \n",
       "...                                        ...      ...  ...   \n",
       "8373               b'Latino/Hispanic American'     b'0'  ...   \n",
       "8374                                  b'Other'     b'0'  ...   \n",
       "8375               b'Latino/Hispanic American'     b'0'  ...   \n",
       "8376  b'Asian/Pacific Islander/Asian-American'     b'0'  ...   \n",
       "8377  b'Asian/Pacific Islander/Asian-American'     b'0'  ...   \n",
       "\n",
       "      d_expected_num_interested_in_me  d_expected_num_matches like  \\\n",
       "0                            b'[0-3]'                b'[3-5]'  7.0   \n",
       "1                            b'[0-3]'                b'[3-5]'  7.0   \n",
       "2                            b'[0-3]'                b'[3-5]'  7.0   \n",
       "3                            b'[0-3]'                b'[3-5]'  7.0   \n",
       "4                            b'[0-3]'                b'[3-5]'  6.0   \n",
       "...                               ...                     ...  ...   \n",
       "8373                         b'[0-3]'                b'[3-5]'  2.0   \n",
       "8374                         b'[0-3]'                b'[3-5]'  4.0   \n",
       "8375                         b'[0-3]'                b'[3-5]'  6.0   \n",
       "8376                         b'[0-3]'                b'[3-5]'  5.0   \n",
       "8377                         b'[0-3]'                b'[3-5]'  4.0   \n",
       "\n",
       "     guess_prob_liked    d_like  d_guess_prob_liked  met  decision  \\\n",
       "0                 6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'   \n",
       "1                 5.0  b'[6-8]'            b'[5-6]'  1.0      b'1'   \n",
       "2                 NaN  b'[6-8]'            b'[0-4]'  1.0      b'1'   \n",
       "3                 6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'   \n",
       "4                 6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'   \n",
       "...               ...       ...                 ...  ...       ...   \n",
       "8373              5.0  b'[0-5]'            b'[5-6]'  0.0      b'0'   \n",
       "8374              4.0  b'[0-5]'            b'[0-4]'  0.0      b'0'   \n",
       "8375              5.0  b'[6-8]'            b'[5-6]'  0.0      b'0'   \n",
       "8376              5.0  b'[0-5]'            b'[5-6]'  0.0      b'0'   \n",
       "8377              5.0  b'[0-5]'            b'[5-6]'  0.0      b'0'   \n",
       "\n",
       "      decision_o  match  \n",
       "0           b'0'   b'0'  \n",
       "1           b'0'   b'0'  \n",
       "2           b'1'   b'1'  \n",
       "3           b'1'   b'1'  \n",
       "4           b'1'   b'1'  \n",
       "...          ...    ...  \n",
       "8373        b'1'   b'0'  \n",
       "8374        b'0'   b'0'  \n",
       "8375        b'0'   b'0'  \n",
       "8376        b'1'   b'0'  \n",
       "8377        b'1'   b'0'  \n",
       "\n",
       "[8378 rows x 123 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"speeddating.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminate columns with too missing values (more than 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_interests_o 12.843160658868467\n",
      "shared_interests_partner 12.735736452613988\n",
      "expected_num_interested_in_me 78.5151587491048\n",
      "expected_num_matches 14.000954881833373\n",
      "['shared_interests_o', 'shared_interests_partner', 'expected_num_interested_in_me', 'expected_num_matches']\n"
     ]
    }
   ],
   "source": [
    "#TODO Check which attributes have missing values \n",
    "nulls = data.isnull()*1\n",
    "# Sum the columns\n",
    "col_sums = nulls.sum()/len(data)*100\n",
    "\n",
    "percetage_10=[]\n",
    "for column in data.columns:\n",
    "    if col_sums[column]>10:\n",
    "        print(column, col_sums[column])\n",
    "        percetage_10.append(column)\n",
    "data=data.drop(columns=percetage_10)\n",
    "print(percetage_10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_null\n",
      "wave\n",
      "gender\n",
      "age\n",
      "age_o\n",
      "d_age\n",
      "d_d_age\n",
      "race\n",
      "race_o\n",
      "samerace\n",
      "importance_same_race\n",
      "importance_same_religion\n",
      "d_importance_same_race\n",
      "d_importance_same_religion\n",
      "field\n",
      "pref_o_attractive\n",
      "pref_o_sincere\n",
      "pref_o_intelligence\n",
      "pref_o_funny\n",
      "pref_o_ambitious\n",
      "pref_o_shared_interests\n",
      "d_pref_o_attractive\n",
      "d_pref_o_sincere\n",
      "d_pref_o_intelligence\n",
      "d_pref_o_funny\n",
      "d_pref_o_ambitious\n",
      "d_pref_o_shared_interests\n",
      "attractive_o\n",
      "sinsere_o\n",
      "intelligence_o\n",
      "funny_o\n",
      "ambitous_o\n",
      "d_attractive_o\n",
      "d_sinsere_o\n",
      "d_intelligence_o\n",
      "d_funny_o\n",
      "d_ambitous_o\n",
      "d_shared_interests_o\n",
      "attractive_important\n",
      "sincere_important\n",
      "intellicence_important\n",
      "funny_important\n",
      "ambtition_important\n",
      "shared_interests_important\n",
      "d_attractive_important\n",
      "d_sincere_important\n",
      "d_intellicence_important\n",
      "d_funny_important\n",
      "d_ambtition_important\n",
      "d_shared_interests_important\n",
      "attractive\n",
      "sincere\n",
      "intelligence\n",
      "funny\n",
      "ambition\n",
      "d_attractive\n",
      "d_sincere\n",
      "d_intelligence\n",
      "d_funny\n",
      "d_ambition\n",
      "attractive_partner\n",
      "sincere_partner\n",
      "intelligence_partner\n",
      "funny_partner\n",
      "ambition_partner\n",
      "d_attractive_partner\n",
      "d_sincere_partner\n",
      "d_intelligence_partner\n",
      "d_funny_partner\n",
      "d_ambition_partner\n",
      "d_shared_interests_partner\n",
      "sports\n",
      "tvsports\n",
      "exercise\n",
      "dining\n",
      "museums\n",
      "art\n",
      "hiking\n",
      "gaming\n",
      "clubbing\n",
      "reading\n",
      "tv\n",
      "theater\n",
      "movies\n",
      "concerts\n",
      "music\n",
      "shopping\n",
      "yoga\n",
      "d_sports\n",
      "d_tvsports\n",
      "d_exercise\n",
      "d_dining\n",
      "d_museums\n",
      "d_art\n",
      "d_hiking\n",
      "d_gaming\n",
      "d_clubbing\n",
      "d_reading\n",
      "d_tv\n",
      "d_theater\n",
      "d_movies\n",
      "d_concerts\n",
      "d_music\n",
      "d_shopping\n",
      "d_yoga\n",
      "interests_correlate\n",
      "d_interests_correlate\n",
      "expected_happy_with_sd_people\n",
      "d_expected_happy_with_sd_people\n",
      "d_expected_num_interested_in_me\n",
      "d_expected_num_matches\n",
      "like\n",
      "guess_prob_liked\n",
      "d_like\n",
      "d_guess_prob_liked\n",
      "met\n",
      "decision\n",
      "decision_o\n",
      "match\n"
     ]
    }
   ],
   "source": [
    "for column in data.columns:\n",
    "    print(column)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVariable\\tDescription\\ngender\\tGender of self\\nage\\tAge of self\\nage_o\\tAge of partner\\nd_age\\tDifference in age\\nd_age\\tDifference in age\\nrace\\tRace of self\\nrace_o\\tRace of partner\\nsamerace\\tWhether the two persons have the same race or not.\\nimportance_same_race\\tHow important is it that partner is of same race?\\nimportance_same_religion\\tHow important is it that partner has same religion?\\nfield\\tField of study\\npref_o_attractive\\tHow important does partner rate attractiveness\\npref_o_sinsere\\tHow important does partner rate sincerity\\npref_o_intelligence\\tHow important does partner rate intelligence\\npref_o_funny\\tHow important does partner rate being funny\\npref_o_ambitious\\tHow important does partner rate ambition\\npref_o_shared_interests\\tHow important does partner rate having shared interests\\nattractive_o\\tRating by partner (about me) at night of event on attractiveness\\nsincere_o\\tRating by partner (about me) at night of event on sincerity\\nintelligence_o\\tRating by partner (about me) at night of event on intelligence\\nfunny_o\\tRating by partner (about me) at night of event on being funny\\nambitous_o\\tRating by partner (about me) at night of event on being ambitious\\nshared_interests_o\\tRating by partner (about me) at night of event on shared interest\\nattractive_important\\tWhat do you look for in a partner - attractiveness\\nsincere_important\\tWhat do you look for in a partner - sincerity\\nintellicence_important\\tWhat do you look for in a partner - intelligence\\nfunny_important\\tWhat do you look for in a partner - being funny\\nambtition_important\\tWhat do you look for in a partner - ambition\\nshared_interests_important\\tWhat do you look for in a partner - shared interests\\nattractive\\tRate yourself - attractiveness\\nsincere\\tRate yourself - sincerity\\nintelligence\\tRate yourself - intelligence\\nfunny\\tRate yourself - being funny\\nambition\\tRate yourself - ambition\\nattractive_partner\\tRate your partner - attractiveness\\nsincere_partner\\tRate your partner - sincerity\\nintelligence_partner\\tRate your partner - intelligence\\nfunny_partner\\tRate your partner - being funny\\nambition_partner\\tRate your partner - ambition\\nshared_interests_partner\\tRate your partner - shared interests\\nsports\\tYour own interests [1-10]\\ninterests_correlate\\tCorrelation between participant’s and partner’s ratings of interests.\\nexpected_happy_with_sd_people\\tHow happy do you expect to be with the people you meet during the speed-dating event?\\nexpected_num_interested_in_me\\tOut of the 20 people you will meet, how many do you expect will be interested in dating you?\\nexpected_num_matches\\tHow many matches do you expect to get?\\nlike\\tDid you like your partner?\\nguess_prob_liked\\tHow likely do you think it is that your partner likes you?\\nmet\\tHave you met your partner before?\\ndecision\\tDecision at night of event.\\ndecision_o\\tDecision of partner at night of event.\\nmatch\\tMatch (yes/no)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Variable\tDescription\n",
    "gender\tGender of self\n",
    "age\tAge of self\n",
    "age_o\tAge of partner\n",
    "d_age\tDifference in age\n",
    "d_age\tDifference in age\n",
    "race\tRace of self\n",
    "race_o\tRace of partner\n",
    "samerace\tWhether the two persons have the same race or not.\n",
    "importance_same_race\tHow important is it that partner is of same race?\n",
    "importance_same_religion\tHow important is it that partner has same religion?\n",
    "field\tField of study\n",
    "pref_o_attractive\tHow important does partner rate attractiveness\n",
    "pref_o_sinsere\tHow important does partner rate sincerity\n",
    "pref_o_intelligence\tHow important does partner rate intelligence\n",
    "pref_o_funny\tHow important does partner rate being funny\n",
    "pref_o_ambitious\tHow important does partner rate ambition\n",
    "pref_o_shared_interests\tHow important does partner rate having shared interests\n",
    "attractive_o\tRating by partner (about me) at night of event on attractiveness\n",
    "sincere_o\tRating by partner (about me) at night of event on sincerity\n",
    "intelligence_o\tRating by partner (about me) at night of event on intelligence\n",
    "funny_o\tRating by partner (about me) at night of event on being funny\n",
    "ambitous_o\tRating by partner (about me) at night of event on being ambitious\n",
    "shared_interests_o\tRating by partner (about me) at night of event on shared interest\n",
    "attractive_important\tWhat do you look for in a partner - attractiveness\n",
    "sincere_important\tWhat do you look for in a partner - sincerity\n",
    "intellicence_important\tWhat do you look for in a partner - intelligence\n",
    "funny_important\tWhat do you look for in a partner - being funny\n",
    "ambtition_important\tWhat do you look for in a partner - ambition\n",
    "shared_interests_important\tWhat do you look for in a partner - shared interests\n",
    "attractive\tRate yourself - attractiveness\n",
    "sincere\tRate yourself - sincerity\n",
    "intelligence\tRate yourself - intelligence\n",
    "funny\tRate yourself - being funny\n",
    "ambition\tRate yourself - ambition\n",
    "attractive_partner\tRate your partner - attractiveness\n",
    "sincere_partner\tRate your partner - sincerity\n",
    "intelligence_partner\tRate your partner - intelligence\n",
    "funny_partner\tRate your partner - being funny\n",
    "ambition_partner\tRate your partner - ambition\n",
    "shared_interests_partner\tRate your partner - shared interests\n",
    "sports\tYour own interests [1-10]\n",
    "interests_correlate\tCorrelation between participant’s and partner’s ratings of interests.\n",
    "expected_happy_with_sd_people\tHow happy do you expect to be with the people you meet during the speed-dating event?\n",
    "expected_num_interested_in_me\tOut of the 20 people you will meet, how many do you expect will be interested in dating you?\n",
    "expected_num_matches\tHow many matches do you expect to get?\n",
    "like\tDid you like your partner?\n",
    "guess_prob_liked\tHow likely do you think it is that your partner likes you?\n",
    "met\tHave you met your partner before?\n",
    "decision\tDecision at night of event.\n",
    "decision_o\tDecision of partner at night of event.\n",
    "match\tMatch (yes/no)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wave</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>...</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8283.000000</td>\n",
       "      <td>8274.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8289.000000</td>\n",
       "      <td>8289.000000</td>\n",
       "      <td>8289.000000</td>\n",
       "      <td>8280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8220.000000</td>\n",
       "      <td>8277.000000</td>\n",
       "      <td>8138.000000</td>\n",
       "      <td>8069.000000</td>\n",
       "      <td>8003.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.350919</td>\n",
       "      <td>26.358928</td>\n",
       "      <td>26.364999</td>\n",
       "      <td>4.185605</td>\n",
       "      <td>3.784793</td>\n",
       "      <td>3.651645</td>\n",
       "      <td>22.495347</td>\n",
       "      <td>17.396867</td>\n",
       "      <td>20.270759</td>\n",
       "      <td>17.459714</td>\n",
       "      <td>...</td>\n",
       "      <td>7.919629</td>\n",
       "      <td>6.825401</td>\n",
       "      <td>7.851066</td>\n",
       "      <td>5.631281</td>\n",
       "      <td>4.339197</td>\n",
       "      <td>0.196010</td>\n",
       "      <td>5.534131</td>\n",
       "      <td>6.134087</td>\n",
       "      <td>5.207523</td>\n",
       "      <td>0.049856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.995903</td>\n",
       "      <td>3.566763</td>\n",
       "      <td>3.563648</td>\n",
       "      <td>4.596171</td>\n",
       "      <td>2.845708</td>\n",
       "      <td>2.805237</td>\n",
       "      <td>12.569802</td>\n",
       "      <td>7.044003</td>\n",
       "      <td>6.782895</td>\n",
       "      <td>6.085526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700927</td>\n",
       "      <td>2.156283</td>\n",
       "      <td>1.791827</td>\n",
       "      <td>2.608913</td>\n",
       "      <td>2.717612</td>\n",
       "      <td>0.303539</td>\n",
       "      <td>1.734059</td>\n",
       "      <td>1.841285</td>\n",
       "      <td>2.129565</td>\n",
       "      <td>0.282168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.830000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.390000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.370000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>23.810000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              wave          age        age_o        d_age  \\\n",
       "count  8378.000000  8283.000000  8274.000000  8378.000000   \n",
       "mean     11.350919    26.358928    26.364999     4.185605   \n",
       "std       5.995903     3.566763     3.563648     4.596171   \n",
       "min       1.000000    18.000000    18.000000     0.000000   \n",
       "25%       7.000000    24.000000    24.000000     1.000000   \n",
       "50%      11.000000    26.000000    26.000000     3.000000   \n",
       "75%      15.000000    28.000000    28.000000     5.000000   \n",
       "max      21.000000    55.000000    55.000000    37.000000   \n",
       "\n",
       "       importance_same_race  importance_same_religion  pref_o_attractive  \\\n",
       "count           8299.000000               8299.000000        8289.000000   \n",
       "mean               3.784793                  3.651645          22.495347   \n",
       "std                2.845708                  2.805237          12.569802   \n",
       "min                0.000000                  1.000000           0.000000   \n",
       "25%                1.000000                  1.000000          15.000000   \n",
       "50%                3.000000                  3.000000          20.000000   \n",
       "75%                6.000000                  6.000000          25.000000   \n",
       "max               10.000000                 10.000000         100.000000   \n",
       "\n",
       "       pref_o_sincere  pref_o_intelligence  pref_o_funny  ...       movies  \\\n",
       "count     8289.000000          8289.000000   8280.000000  ...  8299.000000   \n",
       "mean        17.396867            20.270759     17.459714  ...     7.919629   \n",
       "std          7.044003             6.782895      6.085526  ...     1.700927   \n",
       "min          0.000000             0.000000      0.000000  ...     0.000000   \n",
       "25%         15.000000            17.390000     15.000000  ...     7.000000   \n",
       "50%         18.370000            20.000000     18.000000  ...     8.000000   \n",
       "75%         20.000000            23.810000     20.000000  ...     9.000000   \n",
       "max         60.000000            50.000000     50.000000  ...    10.000000   \n",
       "\n",
       "          concerts        music     shopping         yoga  \\\n",
       "count  8299.000000  8299.000000  8299.000000  8299.000000   \n",
       "mean      6.825401     7.851066     5.631281     4.339197   \n",
       "std       2.156283     1.791827     2.608913     2.717612   \n",
       "min       0.000000     1.000000     1.000000     0.000000   \n",
       "25%       5.000000     7.000000     4.000000     2.000000   \n",
       "50%       7.000000     8.000000     6.000000     4.000000   \n",
       "75%       8.000000     9.000000     8.000000     7.000000   \n",
       "max      10.000000    10.000000    10.000000    10.000000   \n",
       "\n",
       "       interests_correlate  expected_happy_with_sd_people         like  \\\n",
       "count          8220.000000                    8277.000000  8138.000000   \n",
       "mean              0.196010                       5.534131     6.134087   \n",
       "std               0.303539                       1.734059     1.841285   \n",
       "min              -0.830000                       1.000000     0.000000   \n",
       "25%              -0.020000                       5.000000     5.000000   \n",
       "50%               0.210000                       6.000000     6.000000   \n",
       "75%               0.430000                       7.000000     7.000000   \n",
       "max               0.910000                      10.000000    10.000000   \n",
       "\n",
       "       guess_prob_liked          met  \n",
       "count       8069.000000  8003.000000  \n",
       "mean           5.207523     0.049856  \n",
       "std            2.129565     0.282168  \n",
       "min            0.000000     0.000000  \n",
       "25%            4.000000     0.000000  \n",
       "50%            5.000000     0.000000  \n",
       "75%            7.000000     0.000000  \n",
       "max           10.000000     8.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of cross-validation:  [0.83484848 0.83484848 0.83560606 0.83560606 0.83548143]\n",
      "Average cross-validation score: 0.83528\n",
      "Test accuracy: 0.83455\n"
     ]
    }
   ],
   "source": [
    "# Create model of logistic regression\n",
    "\n",
    "variables1_X=[\"pref_o_attractive\",\"pref_o_sincere\",\"pref_o_intelligence\",\"pref_o_funny\",\"pref_o_ambitious\",\"pref_o_shared_interests\"]\n",
    "label_y=[\"match\"]\n",
    "variables1=variables1_X+label_y\n",
    "data_model1=data[variables1]\n",
    "data_model1= data_model1.dropna(how='any')\n",
    "data_model1 = pd.get_dummies(data_model1, columns=label_y)\n",
    "\n",
    "# Load your dataset into X and y\n",
    "X =data_model1[variables1_X]\n",
    "y =data_model1[data_model1.columns[-1]]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "clf = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "k = 5\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=k)\n",
    "print( \"Accuracy of cross-validation: \", scores)\n",
    "# Print the average accuracy across all folds\n",
    "print(\"Average cross-validation score: %.5f\" % np.mean(scores))\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "test_score = clf.score(X_test, y_test)\n",
    "print(\"Test accuracy: %.5f\" % test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 1, 'penalty': 'l2'}\n",
      "Best cross-validation score: 0.82566\n",
      "Test accuracy: 0.81835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\afrincon\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\afrincon\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\afrincon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\afrincon\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\afrincon\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.82518465        nan 0.82565623        nan 0.82565623]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "table_models = pd.DataFrame(columns=['Model', 'Train accuracy', 'Test accuracy', 'Observations'])\n",
    "\n",
    "# Create model of logistic regression\n",
    "\n",
    "variables2_X=[\"d_age\",\"intelligence_o\",\"funny_o\"]\n",
    "label_y=[\"match\"]\n",
    "variables2=variables2_X+label_y\n",
    "data_model2=data[variables2]\n",
    "data_model2= data_model2.dropna(how='any')\n",
    "data_model2 = pd.get_dummies(data_model2, columns=label_y)\n",
    "# Load your dataset into X and y\n",
    "X =data_model2[variables2_X]\n",
    "y =data_model2[data_model1.columns[-1]]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression classifier\n",
    "clf = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Create the Grid Search object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the Grid Search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: %.5f\" % grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best estimator on the test data\n",
    "test_score = grid_search.best_estimator_.score(X_test, y_test)\n",
    "print(\"Test accuracy: %.5f\" % test_score)\n",
    "##Add to model to dataframe\n",
    "table_models.loc[0] = ['Logistic Regression', grid_search.best_score_, test_score, \"This model uses a logistic regression using d_age, intelligence_o, funny_o as indepedent variables\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.825656</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>This model uses a logistic regression using d_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train accuracy  Test accuracy  \\\n",
       "0  Logistic Regression        0.825656       0.818353   \n",
       "\n",
       "                                        Observations  \n",
       "0  This model uses a logistic regression using d_...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_models "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 3, 'min_samples_split': 2}\n",
      "Training accuracy with best hyperparameters: 0.83100\n",
      "Test accuracy with best hyperparameters: 0.82150\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Create the classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best hyperparameters to create a new classifier\n",
    "best_clf = DecisionTreeClassifier(random_state=42, **grid_search.best_params_)\n",
    "\n",
    "# Train the new classifier on the training data\n",
    "best_clf.fit(X_train, y_train)\n",
    "train_score=best_clf.score(X_train, y_train)\n",
    "print(\"Training accuracy with best hyperparameters: %.5f\" % train_score)\n",
    "# Evaluate the new classifier on the test data\n",
    "test_score = best_clf.score(X_test, y_test)\n",
    "print(\"Test accuracy with best hyperparameters: %.5f\" % test_score)\n",
    "table_models.loc[1] = ['Decision Tree', train_score, test_score, \"This model uses a decision tree with max_depth=7 indepent variables as d_age, intelligence_o, funny_o as indepedent variables\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.825656</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>This model uses a logistic regression using d_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.831001</td>\n",
       "      <td>0.821496</td>\n",
       "      <td>This model uses a decision tree with max_depth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train accuracy  Test accuracy  \\\n",
       "0  Logistic Regression        0.825656       0.818353   \n",
       "1        Decision Tree        0.831001       0.821496   \n",
       "\n",
       "                                        Observations  \n",
       "0  This model uses a logistic regression using d_...  \n",
       "1  This model uses a decision tree with max_depth...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 3, 'min_samples_split': 2}\n",
      "Training accuracy with best hyperparameters: 0.83100\n",
      "Test accuracy with best hyperparameters: 0.82150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by the grid search\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best hyperparameters to create a new classifier\n",
    "best_clf = RandomForestClassifier(random_state=42, **grid_search.best_params_)\n",
    "\n",
    "# Train the new classifier on the training data\n",
    "best_clf.fit(X_train, y_train)\n",
    "train_score=best_clf.score(X_train, y_train)\n",
    "print(\"Training accuracy with best hyperparameters: %.5f\" % train_score)\n",
    "# Evaluate the new classifier on the test data\n",
    "test_score = best_clf.score(X_test, y_test)\n",
    "print(\"Test accuracy with best hyperparameters: %.5f\" % test_score)\n",
    "table_models.loc[2] = ['Random Forest', train_score, test_score, \"This model uses a random forest with max_depth=7 and with indepent variables as d_age, intelligence_o, funny_o as indepedent variables\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.825656</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>This model uses a logistic regression using d_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.831001</td>\n",
       "      <td>0.821496</td>\n",
       "      <td>This model uses a decision tree with max_depth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.831001</td>\n",
       "      <td>0.821496</td>\n",
       "      <td>This model uses a random forest with max_depth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train accuracy  Test accuracy  \\\n",
       "0  Logistic Regression        0.825656       0.818353   \n",
       "1        Decision Tree        0.831001       0.821496   \n",
       "2        Random Forest        0.831001       0.821496   \n",
       "\n",
       "                                        Observations  \n",
       "0  This model uses a logistic regression using d_...  \n",
       "1  This model uses a decision tree with max_depth...  \n",
       "2  This model uses a random forest with max_depth...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74849095 0.69818913 0.77263581 0.8194165 ]\n",
      " [0.70573441 0.73189135 0.77263581 0.8194165 ]\n",
      " [0.71830986 0.80482897 0.81891348 0.8194165 ]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create SVM models with different values of C and gamma\n",
    "coef0s = [-1, 0, 1]\n",
    "gammas = [0.01, 0.1, 1, 10]\n",
    "models = []\n",
    "scores_training=[]\n",
    "for c in coef0s:\n",
    "    for gamma in gammas:\n",
    "        model = SVC(kernel='sigmoid', coef0=c, gamma=gamma, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        score_train = model.score(X_train, y_train)\n",
    "        scores_training.append(score_train)\n",
    "        models.append(model)\n",
    "\n",
    "# Evaluate the models on the testing data\n",
    "scores_testing = []\n",
    "for model in models:\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores_testing.append(score)\n",
    "# Plot the scores as a heatmap\n",
    "scores = np.array(scores_testing).reshape(len(coef0s), len(gammas))\n",
    "plt.imshow(scores, interpolation='nearest', cmap='coolwarm')\n",
    "plt.xticks(np.arange(len(gammas)), gammas, rotation=45)\n",
    "plt.yticks(np.arange(len(coef0s)), coef0s)\n",
    "plt.xlabel(r'$\\beta_0$')\n",
    "plt.ylabel(r'$\\beta_1$')\n",
    "plt.colorbar()\n",
    "plt.title('Accuracy of SVM with Sigmoid Kernel')\n",
    "plt.show()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_models.loc[3] = ['SVM with kernel: sigmoid', scores_training[-1], scores[-1][-1], 'This model uses a SVM with a sigmoid kernel (beta_0=10 and beta_1=1) and indepent variables as d_age, intelligence_o, funny_o as indepedent variables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.825656</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>This model uses a logistic regression using d_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.831001</td>\n",
       "      <td>0.821496</td>\n",
       "      <td>This model uses a decision tree with max_depth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.831001</td>\n",
       "      <td>0.821496</td>\n",
       "      <td>This model uses a random forest with max_depth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM with kernel: sigmoid</td>\n",
       "      <td>0.832327</td>\n",
       "      <td>0.819416</td>\n",
       "      <td>This model uses a SVM with a sigmoid kernel (b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Train accuracy  Test accuracy  \\\n",
       "0       Logistic Regression        0.825656       0.818353   \n",
       "1             Decision Tree        0.831001       0.821496   \n",
       "2             Random Forest        0.831001       0.821496   \n",
       "3  SVM with kernel: sigmoid        0.832327       0.819416   \n",
       "\n",
       "                                        Observations  \n",
       "0  This model uses a logistic regression using d_...  \n",
       "1  This model uses a decision tree with max_depth...  \n",
       "2  This model uses a random forest with max_depth...  \n",
       "3  This model uses a SVM with a sigmoid kernel (b...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
